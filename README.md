# AI-Powered Contract Processing System

## Overview
The **AI-Powered Contract Processing System** automates the extraction, summarization, and analysis of legal contracts using advanced **Generative AI**.  
It helps legal teams save time by automatically identifying key clauses, summarizing lengthy documents, redacting sensitive information, and calculating risk scores.

This system supports **PDF, DOCX, PPTX, XLSX, TXT, and image formats (JPG, PNG)**.

---

## AI Architecture

### ğŸ”¹ Core Workflow
1. **Document Ingestion** â€“ The system accepts multiple formats (PDF, DOCX, PPTX, XLSX, TXT, images).  
2. **Text Extraction** â€“ Uses libraries like **PyMuPDF**, **python-docx**, **python-pptx**, **openpyxl**, and **EasyOCR** for OCR text extraction.  
3. **Entity & Clause Analysis** â€“ Key clauses (e.g., parties, dates, obligations) are extracted using rule-based and LLM-powered entity recognition.  
4. **Summarization & Risk Scoring** â€“ The **llama-3.3-70b-versatile** generates summaries and calculates a risk score.  
5. **Redaction** â€“ Sensitive information such as PII (names, emails, contact numbers) is automatically masked.  
6. **Output Generation** â€“ A concise report is returned to the user with key insights and risks.

### ğŸ”¹ Components Used
- **FastAPI** â€“ REST API Framework  
- **Groq API (llama-3.3-70b-versatile)** â€“ For AI-driven summarization & risk analysis  
- **EasyOCR** â€“ For OCR-based image text extraction  
- **Ollama (gemma3:4b)** â€“ For local model inference without cloud API  
- **dotenv** â€“ To manage API keys securely  
- **NumPy, PyMuPDF, OpenPyXL, python-docx, python-pptx** â€“ For text extraction  

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create and Activate Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate      # (Windows)
# or
source venv/bin/activate   # (macOS/Linux)
``` 
### 2ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```
### 3ï¸âƒ£ Set Environment Variables

In config.py
```
GROQ_API_KEY=your_groq_api_key_here
```
### Run the Application

Start the FastAPI server:
```
uvicorn app.main:app --reload
```

Once the server starts, run the streamlit page:
```
streamlit run 
```

If you prefer local model inference:
```
ollama pull llama3:latest
```

Then in config.py, switch the model provider:
```
USE_GROQ = False  # Set to False to use Ollama
```
## Folder architecture
AI-Powered-Contract-Processing-System /
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ contract.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_client.py
â”‚   â”‚   â”œâ”€â”€ parser.py
â”‚   â”‚   â”œâ”€â”€ redactor.py
â”‚   â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”‚   â””â”€â”€ risk_calculator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ schema.py
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_contract_agent.py
